Short introduction :
Alenka supports several data types : integers, floats, decimals(2 digits after a separator) and character strings.
The difference between floats and decimals is that the latter will be compressed when written to a file.

Loading data for processing : 
Alenka can read text files with fields separated by separators. But much faster way to read the data would be to load it into binary files as demonstrated by the following script :

C := STREAM 'date.tbl' USING ('|') AS (d_datekey{1}:int, d_month{4}:varchar(9), d_year{5}:int, d_yearmonthnum{6}:int, d_yearmonth{7}:varchar(7), 
                                            d_weeknuminyear{12}:int);
STORE C INTO 'date' BINARY;

This script read file date.tbl with fields separated by tabs. Field d_datekey is the first field in a file, d_month - fourth field and so on.
Since alenka is a columnar database the fields will be compressed and stored in separate files with names like date.1, date.4 etc.

Compression. In Alenka compression and decompression is transparent to the user. Alenka uses FOR(frame of reference), FOR-DELTA and dictionary compression.
Decimal and integer fields are compressed by FOR and FOR-DELTA(when data are already sorted). Strings are compressed by dictionary compression.
Like all other oparations compression and decompression are done on the GPU.

Once we created the data files we can do the data processing : 

L := STREAM 'lineorder' BINARY AS (lo_partkey{4}:int, lo_suppkey{5}:int, lo_orderdate{6}:int, lo_revenue{13}:decimal);
D := LOAD 'date' BINARY AS (d_datekey{1}:int, d_year{5}:int);
S := LOAD 'supplier' BINARY AS (s_suppkey{1}:int, s_region{6}:varchar(12));
P := LOAD 'part' BINARY AS (p_partkey{1}:int,  p_category{4}:varchar(12),  p_brand1{5}:varchar(9));

PF := FILTER P BY p_category == "MFGR#12";
SF := FILTER S BY s_region == "AMERICA";

LS := SELECT lo_revenue AS lo_revenue,  lo_partkey AS lo_partkey, lo_orderdate as lo_orderdate,
             lo_partkey AS lo_partkey
      FROM L JOIN SF on lo_suppkey = s_suppkey;

J := SELECT lo_revenue AS lo_revenue, p_brand1 AS p_brand1, lo_orderdate as lo_orderdate
      FROM LS JOIN PF on lo_partkey = p_partkey;	  
	  
LD := SELECT lo_revenue AS lo_revenue, d_year AS d_year, p_brand1 AS p_brand1
      FROM J JOIN D on lo_orderdate = d_datekey;	  
	  
R := SELECT SUM(lo_revenue) AS lo_revenue, d_year AS d_year, p_brand1 AS p_brand1 FROM LD
     GROUP BY d_year, p_brand1;
	 
R1 := ORDER R BY d_year, p_brand1;	 
	 
STORE R1 INTO 'ss21.txt' USING ('|');

Notice the difference between STREAM load and regular LOAD statements : file loaded with STREAM will be loaded and processed piece by piece. Files loaded by regular LOAD statement will be fully loaded into host memory.

To compile alenka you need to download NVidia's CUDA. 
Install it and run the following commands to compile alenka executable : 
For Win64 :
  nvcc.exe -arch sm_13 -L "C:\Program Files\Microsoft Visual Studio 10.0\VC\lib\amd64" -lcuda C:\GnuWin32\bin\bison.cu -o alenka
For Linux :
  nvcc -arch sm_13 -lcuda ./bison.cu -o ./alenka

if you compile for Win64 platform.
I tested Alenka on Windows7, the results on other platforms may vary :-)
When you compiled alenka you can run it from a command line using a SQL script file as a parameter : alenka.exe q1.sql 
I tested alenka on first six TPC-H queries with scale 100 (600 million records) and on all Star Query Benchmarks with scale 1000(6 billion records).

Alenka is distributed under Apache 2 license.

antonmks@gmail.com  
 

